{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "Train an Agent on Unity ML-Agents environment to navigate and collect as many yellow bananas as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import torch\n",
    "import numpy as np\n",
    "from unityagents import UnityEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed    = 42   # initialize the seed to get similar outcomes\n",
    "# device  = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # initialize the device\n",
    "# print(\"Device: {}\".format(device))\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "# setup the environment by providing the path to the env file\n",
    "env = UnityEnvironment(file_name=\"Banana_Linux/Banana.x86_64\", seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "# brains are responsible for deciding the actions of their associated agents\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States look like: [0.         1.         0.         0.         0.78926337 0.\n",
      " 1.         0.         0.         0.55464244 0.         1.\n",
      " 0.         0.         0.42521358 0.         1.         0.\n",
      " 0.         0.56680632 0.         1.         0.         0.\n",
      " 0.46538338 0.         1.         0.         0.         0.51788217\n",
      " 0.         0.         1.         0.         0.39806581 0.\n",
      " 0.        ]\n",
      "States have length: 37\n"
     ]
    }
   ],
   "source": [
    "# examine the state and action spaces\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required torch libraries\n",
    "from torch import nn\n",
    "\n",
    "class DQNetwork(nn.Module):\n",
    "    \"\"\" A Deep-Q-Network model. \"\"\"\n",
    "    def __init__(self, state_size, action_size, seed):\n",
    "        \"\"\" Initialize parameters and build model. \n",
    "        Parameters\n",
    "        ----------\n",
    "            state_size (int):   Dimension of each state\n",
    "            action_size (int):  Dimension of each action\n",
    "            seed(int):          Random seed\n",
    "        \"\"\"\n",
    "        super(DQNetwork, self).__init__()\n",
    "        self.seed   = torch.manual_seed(seed)\n",
    "\n",
    "        # Define the fully connected layers\n",
    "        self.fc1    = nn.Linear(state_size, 128)\n",
    "        self.relu1  = nn.ReLU()\n",
    "        self.bn1    = nn.BatchNorm1d(128)\n",
    "        self.do1    = nn.Dropout(0.1)\n",
    "\n",
    "        self.fc2    = nn.Linear(128, 64)\n",
    "        self.relu2  = nn.ReLU()\n",
    "        self.bn2    = nn.BatchNorm1d(64)\n",
    "        self.do2    = nn.Dropout(0.1)\n",
    "\n",
    "        self.fc3    = nn.Linear(64, 32)\n",
    "        self.relu3  = nn.ReLU()\n",
    "        self.bn3    = nn.BatchNorm1d(32)\n",
    "        self.do3    = nn.Dropout(0.1)\n",
    "\n",
    "        self.out    = nn.Linear(32, action_size)\n",
    "    \n",
    "    def forward(self, state):\n",
    "        x = self.do1(self.bn1(self.relu1(self.fc1(state))))\n",
    "        x = self.do2(self.bn2(self.relu2(self.fc2(x))))\n",
    "        x = self.do3(self.bn3(self.relu3(self.fc3(x))))\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\" Fixed-size buffer to store experience tuples. \"\"\"\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        \"\"\" Initialize Replay buffer\n",
    "        Parameters\n",
    "        ----------\n",
    "            action_size (int):  Dimension of each action\n",
    "            buffer_size (int):  Maximum size of buffer\n",
    "            batch_size (int):   Size of each training batch\n",
    "            seed (int):         Random seed\n",
    "        \"\"\"\n",
    "        self.action_size    = action_size\n",
    "        self.memory         = deque(maxlen=buffer_size)\n",
    "        self.batch_size     = batch_size\n",
    "        self.experience     = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed           = random.seed(seed)\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\" Add a new experience to memory. \"\"\"\n",
    "        self.memory.append(self.experience(state, action, reward, next_state, done))\n",
    "        \n",
    "    def sample(self):\n",
    "        \"\"\" Select Random samples of batch size\"\"\"\n",
    "\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "        states      = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions     = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
    "        rewards     = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones       = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "\n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\" Return the current size of internal memory. \"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Agent():\n",
    "    \"\"\" An agent interacts with environment and learns from it. \"\"\"\n",
    "    def __init__(self, state_size, action_size, seed):\n",
    "        \"\"\" Initialize the agent \"\"\"\n",
    "        self.state_size     = state_size\n",
    "        self.action_size    = action_size\n",
    "        self.seed           = random.seed(seed)\n",
    "\n",
    "        # Hyper parameters\n",
    "        self.lr             = 5e-4      # learning rate\n",
    "        self.gamma          = 0.99      # discount factor\n",
    "        self.batch_size     = 64        # minibatch size for training\n",
    "        self.tau            = 1e-3      # soft update weight for target params\n",
    "        self.buffer_size    = int(1e7)  # replay buffer size\n",
    "        self.local_update_freq    = 4   # how often to update the local network\n",
    "        self.target_update_freq   = self.local_update_freq * 4 # how often to update target network\n",
    "        \n",
    "        # DQ-Network\n",
    "        self.q_network_local    = DQNetwork(self.state_size, self.action_size, seed)\n",
    "        self.q_network_target   = DQNetwork(self.state_size, self.action_size, seed)\n",
    "        self.optimizer          = optim.Adam(self.q_network_local.parameters(), lr=self.lr, weight_decay=1e-5)\n",
    "        \n",
    "        # Replay memory\n",
    "        self.memory     = ReplayBuffer(self.action_size, self.buffer_size, self.batch_size, seed)\n",
    "        # Initialize time step (for updating every \"update_freq\" steps)\n",
    "        self.t_step_local   = 0\n",
    "        self.t_step_target  = 0\n",
    "        \n",
    "    def act(self, state, eps=0.0):\n",
    "        \"\"\" Returns action for given state as per current policy.\n",
    "        Parameters\n",
    "        ----------\n",
    "            state (array_like): Current_state\n",
    "            eps (float):        Epsilon, for epsilon-greedy action selection\n",
    "        \"\"\"\n",
    "        state = torch.from_numpy(np.array(state.tolist())).float().unsqueeze(0).to(device)\n",
    "        \n",
    "        # Set the network to evaluation mode\n",
    "        self.q_network_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.q_network_local(state)\n",
    "\n",
    "        # Set the network back to training mode\n",
    "        self.q_network_local.train()\n",
    "\n",
    "        # Epsilon-greedy action selection\n",
    "        if random.random() > eps:\n",
    "            return np.argmax(action_values.cpu().data.numpy())\n",
    "        else:\n",
    "            return random.choice(np.arange(self.action_size))\n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau: float):\n",
    "        \"\"\" Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "        Parameters\n",
    "        ----------\n",
    "            local_model (PyTorch model):    weights will be copied from\n",
    "            target_model (PyTorch model):   weights will be copied to\n",
    "            tau (float):                    interpolation parameter\n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0 - tau)*target_param.data)\n",
    "                \n",
    "    def learn(self, experiences, gamma):\n",
    "        \"\"\" Update value parameters using given batch of experience tuples. \n",
    "        Parameters\n",
    "        ----------\n",
    "            experiences (Tuple[torch.Variable]):    tuple of (s, a, r, s', done) tuples\n",
    "            gamma (float):                          discount factor\n",
    "        \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "        # Get max predicted Q values (for next states) from target model\n",
    "        Q_targets_next = self.q_network_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "        # Compute Q targets for current states\n",
    "        # if done add only reward, if not add the discounted expected value\n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "        # Get expected Q values from local model\n",
    "        Q_expected = self.q_network_local(states).gather(1, actions)\n",
    "    \n",
    "        # Compute loss\n",
    "        loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        # Minimize the loss\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # ------------------ Update the target network -------------------#\n",
    "        if (self.t_step_target == 0):\n",
    "            self.soft_update(self.q_network_local, self.q_network_target, self.tau)\n",
    "\n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        # Save experience in replay memory\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "\n",
    "        # Learn every \"update_freq\" steps\n",
    "        self.t_step_local = (self.t_step_local + 1) % self.local_update_freq\n",
    "        self.t_step_target = (self.t_step_target + 1) % self.target_update_freq\n",
    "        \n",
    "        if (self.t_step_local == 0):\n",
    "            # If enough samples are available in memory, get random subset and learn\n",
    "            if len(self.memory) > self.batch_size:\n",
    "                experiences = self.memory.sample()\n",
    "                self.learn(experiences, self.gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(state_size, action_size, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dqn(num_episodes=2000, max_t=1000, eps_start=1.0, eps_end=0.001, eps_decay=0.995):\n",
    "    \"\"\" Deep Q-Learning.\n",
    "    Parameters\n",
    "    ----------\n",
    "        n_episodes (int):   Maximum number of training episodes\n",
    "        max_t (int):        Maximum number of timesteps per episode\n",
    "        eps_start (float):  Starting value of epsilon, for epsilon-greedy policy\n",
    "        eps_end (float):    Minimum value of epsilon\n",
    "        eps_decay (float):  Decay rate of epsilon over the time\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    scores_window = deque(maxlen=100)\n",
    "    eps     = eps_start\n",
    "\n",
    "    for i_episode in range(1, num_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]       # reset the environment\n",
    "        state = env_info.vector_observations[0]                 # get the current state\n",
    "        score = 0                                               # initialize the score\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state)                           # select an action\n",
    "            env_info = env.step(action)[brain_name]             # send the action to the environment\n",
    "            next_state = env_info.vector_observations[0]        # get the next state\n",
    "            reward = env_info.rewards[0]                        # get the reward\n",
    "            done = env_info.local_done[0]                       # see if episode has finished\n",
    "            agent.step(state, action, reward, next_state, done) # step for the agent to learn from the outcome\n",
    "            score += reward                                     # update the score\n",
    "            state = next_state                                  # roll over the state to next time step\n",
    "            if done:                                            # exit loop if episode finished\n",
    "                break\n",
    "        scores.append(score)\n",
    "        scores_window.append(score)\n",
    "        eps = max(eps_end, eps_decay*eps)\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window))) \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 0.62\n",
      "Episode 200\tAverage Score: 1.63\n",
      "Episode 300\tAverage Score: 5.74\n",
      "Episode 400\tAverage Score: 4.92\n",
      "Episode 500\tAverage Score: 5.24\n",
      "Episode 600\tAverage Score: 8.24\n",
      "Episode 700\tAverage Score: 8.86\n",
      "Episode 800\tAverage Score: 11.93\n",
      "Episode 900\tAverage Score: 14.01\n",
      "Episode 1000\tAverage Score: 14.57\n",
      "Episode 1100\tAverage Score: 15.50\n",
      "Episode 1200\tAverage Score: 16.64\n",
      "Episode 1300\tAverage Score: 16.44\n",
      "Episode 1400\tAverage Score: 17.10\n",
      "Episode 1500\tAverage Score: 16.46\n",
      "Episode 1600\tAverage Score: 16.99\n",
      "Episode 1700\tAverage Score: 16.95\n",
      "Episode 1800\tAverage Score: 16.92\n",
      "Episode 1900\tAverage Score: 17.65\n",
      "Episode 2000\tAverage Score: 17.09\n"
     ]
    }
   ],
   "source": [
    "scores = dqn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# plot the scores\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(agent.q_network_local.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights from file\n",
    "agent.q_network_local.load_state_dict(torch.load('model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 21.0\n"
     ]
    }
   ],
   "source": [
    "# Watch the trained agent navigating and doing its task\n",
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = agent.act(state)                      # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
